@article{Llamas2020,
  doi = {10.3390/rs12040665},
  url = {https://doi.org/10.3390/rs12040665},
  year = {2020},
  month = feb,
  publisher = {{MDPI} {AG}},
  volume = {12},
  number = {4},
  pages = {665},
  author = {Ricardo M. Llamas and Mario Guevara and Danny Rorabaugh and Michela Taufer and Rodrigo Vargas},
  title = {Spatial Gap-Filling of {ESA} {CCI} Satellite-Derived Soil Moisture Based on Geostatistical Techniques and Multiple Regression},
  journal = {Remote Sensing}
}
@ARTICLE{Gao2020,  
	author={T. {Gao} and Y. {Guo} and B. {Zhang} and P. {Cicotti} and Y. {Lu} and P. {Balaji} and M. {Taufer}},
      	journal={IEEE Transactions on Parallel and Distributed Systems},
     	title={Memory-Efficient and Skew-Tolerant MapReduce Over MPI for Supercomputing Systems},
     	year={2020}, 
       	volume={31},
      	number={12},
      	pages={2734-2748}
}
@ARTICLE{CarrilloCabada2019,
  author={H. {Carrillo-Cabada} and J. {Benson} and A. {Razavi} and B. {Mulligan} and M. A. {Cuendet} and H. {Weinstein} and M. {Taufer} and T. {Estrada}},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics},
  title={A Graphic Encoding Method for Quantitative Classification of Protein Structure and Representation of Conformational Changes},
  year={2019},
  volume={},
  number={},
  pages={1-1},
}
@article{Chapp2020,
  doi = {10.14529/jsfi200106},
  author = {Dylan Chapp, Victoria Stodden, and Michela Taufer},
  url = {https://doi.org/10.14529/jsfi200106},
  year = {2020},
  month = mar,
  publisher = {{FSAEIHE} South Ural State University (National Research University)},
  volume = {7},
  number = {1},
  title = {Building a Vision for Reproducibility in the Cyberinfrastructure Ecosystem: Leveraging Community Efforts},
  journal = {Supercomputing Frontiers and Innovations}
}
@article{Taufer2020,
  doi = {10.1098/rsta.2019.0063},
  url = {https://doi.org/10.1098/rsta.2019.0063},
  year = {2020},
  month = jan,
  publisher = {The Royal Society},
  volume = {378},
  number = {2166},
  pages = {20190063},
  author = {Michela Taufer and Trilce Estrada and Travis Johnston},
  title = {A survey of algorithms for transforming molecular dynamics data into metadata for
		            in situ
		            analytics based on machine learning methods},
  journal = {Philosophical Transactions of the Royal Society A: Mathematical,  Physical and Engineering Sciences}
}
@article{Chapp2019,
author = {Dylan Chapp and Danny Rorabaugh and Kento Sato and Dong H Ahn and Michela Taufer},
title ={A three-phase workflow for general and expressive representations of nondeterminism in HPC applications},
journal = {The International Journal of High Performance Computing Applications},
volume = {33},
number = {6},
pages = {1175-1184},
year = {2019},
doi = {10.1177/1094342019868826},

URL = {
        https://doi.org/10.1177/1094342019868826

},
eprint = {
        https://doi.org/10.1177/1094342019868826
}
,
abstract = { Nondeterminism is an increasingly entrenched property of high-performance computing (HPC) applications and has recently been shown to seriously hamper debugging and reproducibility efforts. Tools for addressing the nondeterministic debugging problem have emerged, but they do not provide methods for systematically cataloging the nondeterminism in a given application. We propose a three-phase workflow for representing executions of nondeterministic message passing interface programs as event graphs, quantifying their structural similarity with graph kernels, and applying machine learning techniques to investigate shared properties across applications. We present an empirical study comparing two graph kernels’ suitability for this task and propose future uses of the methodology. }
}
@article{Searles2019,
title = {Creating a Portable, High-Level Graph Analytics Paradigm for Compute and Data-Intensive Applications},
year = {2019},
issue_date = {January 2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {1},
issn = {1740-0562},
author - {R. Searles, S. Herbein, T. Johnston, M. Taufer, and S. Chandrasekaran}
abstract = {HPC offers tremendous potential to process large amounts of data often termed as big data. Distributing data efficiently and leveraging specialised hardware e.g., accelerators are critical in order to best utilise HPC platforms constituting of heterogeneous and distributed systems. In this paper, we develop a portable, high-level paradigm for such systems to run big data applications, more specifically, graph analytics applications popular in the big data and machine learning communities. Using our paradigm, we accelerate three real-world, compute and data intensive, graph analytics applications: a function call graph similarity application, a triangle enumeration subroutine, and a graph assaying application. Our paradigm utilises the MapReduce framework, Apache Spark, in conjunction with CUDA and simultaneously takes advantage of automatic data distribution and accelerator on each node of the system. We demonstrate scalability and parameter space exploration and offer a portable solution to leverage almost any legacy, current, or next-generation HPC or cloud-based system.},
journal = {Int. J. High Perform. Comput. Netw.},
month = jan,
pages = {105–118},
numpages = {14}
}
@misc {Llamas2019,
	Title = {Spatial Gap-Filling of ESA CCI Satellite-Derived Soil Moisture Based on Linear Geostatistics},
	Author = {Llamas, Ricardo and Guevara, Mario and Rorabaugh, Danny and Taufer, Michela and Vargas, Rodrigo},
	DOI = {10.20944/preprints201909.0126.v1},
	Publisher = {Preprints.org},
	Year = {2019},
	URL = {https://doi.org/10.20944/preprints201909.0126.v1},
}
@article{deelman2018,
author = {Deelman, Ewa and Peterka, Tom and Altintas, Ilkay and Carothers, Christopher D and van Dam, Kerstin Kleese and Moreland, Kenneth and Parashar, Manish and Ramakrishnan, Lavanya and Taufer, Michela and Vetter, Jeffrey},
title = {The Future of Scientific Workflows},
year = {2018},
issue_date = {1 2018},
publisher = {Sage Publications, Inc.},
address = {USA},
volume = {32},
number = {1},
issn = {1094-3420},
abstract = {Today's computational, experimental, and observational sciences rely on computations that involve many related tasks. The success of a scientific mission often hinges on the computer automation of these workflows. In April 2015, the US Department of Energy DOE invited a diverse group of domain and computer scientists from national laboratories supported by the Office of Science, the National Nuclear Security Administration, from industry, and from academia to review the workflow requirements of DOE's science and national security missions, to assess the current state of the art in science workflows, to understand the impact of emerging extreme-scale computing systems on those workflows, and to develop requirements for automated workflow management in future and existing environments. This article is a summary of the opinions of over 50 leading researchers attending this workshop. We highlight use cases, computing systems, workflow needs and conclude by summarizing the remaining challenges this community sees that inhibit large-scale scientific workflows from becoming a mainstream tool for extreme-scale science.},
journal = {Int. J. High Perform. Comput. Appl.},
month = jan,
pages = {159–175},
numpages = {17},
keywords = {workflow models, Scientific workflows, extreme-scale computing, distributed computing, in situ computing}
}
@article{chapp2018,
  doi = {10.14529/jsfi180102},
  author = {Dylan Chapp, Kento Sato, Dong H Ahn, and Michela Taufer},
  url = {https://doi.org/10.14529/jsfi180102},
  year = {2018},
  month = mar,
  publisher = {{FSAEIHE} South Ural State University (National Research University)},
  volume = {5},
  number = {1},
  title = {Record-and-Replay Techniques for {HPC} Systems: A Survey},
  journal = {Supercomputing Frontiers and Innovations}
}




